{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Backpropagation](backpropagation1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"backpropagation1.png\" alt=\"Açıklama Metni\" style=\"width:50%; height:50%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function: Q(x) = 1 / (1 + e^(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) \n",
    "\n",
    "sigmoid(3)\n",
    "\n",
    "\n",
    "# Sigmoid Derivative: Q'(x) = Q(x) * (1 - Q(x))\n",
    "def sigmoid_derivative(sigmoid_output):\n",
    "    return sigmoid(sigmoid_output) * (1 - sigmoid(sigmoid_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Function (Activation Function) \n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "The derivative of the sigmoid function is:\n",
    "\n",
    "$$\n",
    "\\sigma'(x) = \\sigma(x) \\cdot (1 - \\sigma(x))\n",
    "$$\n",
    "\n",
    "- np.exp(x) -> it means ${e^x}$, where e is Euler's number (approximately equal to 2.71828).\n",
    "- np.exp supports both scalar and array inputs.\n",
    "- math.exp(x) -> it also means ${e^x}$, but only supports scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "x1 = 0.5\n",
    "x2 = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected output\n",
    "y_expected = 1\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights\n",
    "\n",
    "w1 = 0.7010\n",
    "w2 = 0.3009\n",
    "w3 = 0.4011\n",
    "w4 = 0.6005\n",
    "w5 = 0.551\n",
    "w6 = 0.4595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurons and activation function step\n",
    "def l1f1(x1,x2):\n",
    "    l1f1_result = x1*w1 + x2*w3 # z1 step\n",
    "    return sigmoid(l1f1_result) # h1 step, activation func applied\n",
    "\n",
    "def l1f2(x1,x2):\n",
    "    l1f2_result = x1*w2 + x2*w4 #z2 step\n",
    "    return sigmoid(l1f2_result) # h2 step, activation func applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "def of1(h1,h2):\n",
    "    of1_result = h1*w5 + h2*w6 # z3 step\n",
    "    return sigmoid(of1_result) # h3 step, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1:  0.616\n",
      "h2:  0.582\n"
     ]
    }
   ],
   "source": [
    "h1 = l1f1(x1,x2)\n",
    "h2 = l1f2(x1,x2)\n",
    "\n",
    "print(\"h1: \", round(h1,3))\n",
    "print(\"h2: \", round(h2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output1:  0.647\n"
     ]
    }
   ],
   "source": [
    "output1 = of1(h1, h2)\n",
    "print(\"output1: \", round(output1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lost / Cost / Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means Squared Error\n",
    "def mse(y_expected, y_predicted):\n",
    "    return (y_expected - y_predicted) ** 2 # y is th e expected output, y_hat is the predicted output\n",
    "\n",
    "# MSE Derivative\n",
    "def mse_derivative(y_expected, y_predicted):\n",
    "    return -2 * (y_expected - y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)\n",
    "\n",
    "The Mean Squared Error (MSE) is a commonly used loss function in machine learning. \n",
    "The formula for MSE is:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_{\\text{expected}, i} - y_{\\text{predicted}, i})^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( N \\) is the total number of samples.\n",
    "\n",
    "\n",
    "The Mean Squared Error (MSE) is defined as:\n",
    "\n",
    "The derivative of MSE with respect to y_predicted is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial y_{\\text{predicted}}} = -\\frac{2}{N} (y_{\\text{expected}} - y_{\\text{predicted}})\n",
    "$$\n",
    "\n",
    "\n",
    "For simplicity, if we omit the $\\frac{1}{N}$ term (e.g., for a single training example or simplicity in implementation), the derivative becomes:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial y_{\\text{predicted}}} = -2 (y_{\\text{expected}} - y_{\\text{predicted}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In our case: Simplification in backpropagation\n",
    "- In backpropagation, the key goal is to compute the gradient of the loss with respect to the weights.\n",
    "\n",
    "- We did not include $\\frac{1}{N}$ factor in the case of MSE because our example is simple, so it does not affect the result much.\n",
    "\n",
    "- In larger neural networks with multiple examples, $\\frac{1}{N}$ to average the gradient, which helps make the weight updates more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.124\n",
      "Expected:  1 | Predicted:  0.647\n"
     ]
    }
   ],
   "source": [
    "first_mse = mse(y_expected, output1)\n",
    "print(\"MSE: \", round(first_mse, 3))\n",
    "print(\"Expected: \", y_expected, \"|\", \"Predicted: \", round(output1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_o1:  -0.706\n"
     ]
    }
   ],
   "source": [
    "# Derivative of the loss function with respect to the output layer (y_predicted)\n",
    "dL_o1 = mse_derivative(y_expected, output1) \n",
    "print(\"dL_o1: \", round(dL_o1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient of the Loss w.r.t. Output $o_1$\n",
    "\n",
    "Derivative of the loss with respect to $o_1$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial o_1} = -2 \\cdot (y_{\\text{expected}} - o_1)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_{\\text{expected}}$ is the true value.\n",
    "- $o_1$ is the predicted output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do1_z3:  0.221\n"
     ]
    }
   ],
   "source": [
    "# Gradient of the loss wrt output\n",
    "do1_z3 = sigmoid_derivative(dL_o1)\n",
    "print(\"do1_z3: \", round(do1_z3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient of Output w.r.t. ${z_3}$ (Pre-activation Output)\n",
    "\n",
    "Using the sigmoid derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial o_1}{\\partial z_3} = \\sigma(z_3) \\cdot (1 - \\sigma(z_3))\n",
    "$$\n",
    "\n",
    "- Chain Rule: Loss Gradient w.r.t. \\(z_3\\)\n",
    "\n",
    "Using the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_3} = \\frac{\\partial L}{\\partial o_1} \\cdot \\frac{\\partial o_1}{\\partial z_3}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw5:  0.136\n",
      "dw6:  0.129\n"
     ]
    }
   ],
   "source": [
    "dw5 = do1_z3 * h1\n",
    "dw6 = do1_z3 * h2\n",
    "print(\"dw5: \", round(dw5, 3))\n",
    "print(\"dw6: \", round(dw6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ${H_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh2_z2 = w6 * do1_z3 * sigmoid_derivative(h2)\n",
    "dw2 = dh2_z2 * x1\n",
    "dw4 = dh2_z2 * x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ${H_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh1_z1 = w5 * do1_z3 * sigmoid_derivative(h1)\n",
    "dw1 = dh1_z1 * x1\n",
    "dw3 = dh1_z1 * x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 -= learning_rate * dw1\n",
    "w2 -= learning_rate * dw2\n",
    "w3 -= learning_rate * dw3\n",
    "w4 -= learning_rate * dw4\n",
    "w5 -= learning_rate * dw5\n",
    "w6 -= learning_rate * dw6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights:\n",
      "w1=0.6996, w2=0.2997, w3=0.4003, \n",
      "w4=0.5998, w5=0.5374, w6=0.4466\n"
     ]
    }
   ],
   "source": [
    "print(f\"Updated Weights:\\nw1={round(w1, 4)}, w2={round(w2, 4)}, w3={round(w3, 4)}, \\nw4={round(w4, 4)}, w5={round(w5, 4)}, w6={round(w6, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "l1f1() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Re-run forward pass to verify improvements\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m z1, h1 \u001b[38;5;241m=\u001b[39m \u001b[43ml1f1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m z2, h2 \u001b[38;5;241m=\u001b[39m l1f2(x1, x2, w2, w4)\n\u001b[0;32m      4\u001b[0m z3, output2 \u001b[38;5;241m=\u001b[39m of1(h1, h2, w5, w6)\n",
      "\u001b[1;31mTypeError\u001b[0m: l1f1() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Re-run forward pass to verify improvements\n",
    "z1, h1 = l1f1(x1, x2, w1, w3)\n",
    "z2, h2 = l1f2(x1, x2, w2, w4)\n",
    "z3, output2 = of1(h1, h2, w5, w6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
